{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deployment\n",
    "\n",
    "This section is as platform-agnostic as possible but application part focuses on Amazon Web Services (AWS). \n",
    "\n",
    "Contents\n",
    "\n",
    "- Cloud Computing\n",
    "- Machine Learning in the Workplace\n",
    "- Deployment \n",
    "\n",
    "After getting familiar with machine learning deployment we'll put these ideas to practice using [Amazon SageMaker](https://aws.amazon.com/sagemaker/) as one way to deploy machine learning models. \n",
    "\n",
    "Questions to answer: \n",
    "\n",
    "- What is the machine learning workflow?\n",
    "- How does **deployment** fit into the machine learning workflow?\n",
    "- What is cloud computing?\n",
    "- Why are we using cloud computing for deploying machine learning models?\n",
    "- Why isn't deployment a part of many machine learning curriculums?\n",
    "- What does it mean for a model to be deployed?\n",
    "- What are the essentail characteristics associated with the code of deployed models?\n",
    "- What are different cloud computing platform we might use to deploy our machine learning models?\n",
    "\n",
    "## Machine Learning Workflow\n",
    "\n",
    "Consists of three components: \n",
    "\n",
    "1. Explore & Process Data\n",
    " - Retrieve data\n",
    " - Clean & Explore: Explore patterns, remove any outliers\n",
    " - Transform and prepare: Data Normalization, train-validation-test split\n",
    "2.  Modeling\n",
    " - Develop & Train Model\n",
    " - Validate / Evaluate Model\n",
    "3. Deployment \n",
    " - Deploy to Production\n",
    " - Monitor and Update Model & Data \n",
    "\n",
    "References: \n",
    "\n",
    "- AWS discusses their definition of the [ML Workflow](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-mlconcepts.html)\n",
    "- Google Cloud Platform (GCP) and their definition of the [ML Worklflow](https://cloud.google.com/ml-engine/docs/tensorflow/ml-solutions-overview)\n",
    "- Microsoft Azure on their definition of the [ML Workflow](https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Computing\n",
    "\n",
    "Can be thought of as transforming an IT product into a service. \n",
    "\n",
    "> Using an internet connected device to log into a cloud computing service to access an IT resource. These IT resources are stored in the clud provider's data center. \n",
    "\n",
    "Other cloud services than cloud storage: \n",
    "\n",
    "- Cloud applications, databases, virtual machines, SageMaker, etc. \n",
    "\n",
    "#### Why use cloud computing?\n",
    "\n",
    "Opt to use cloud computing services due time and cost constraints of building own capacities (see capacity utilization graph below). The graph shows schematically how cloud computing compares to traditinoal infrastructure related to customer demand.\n",
    "\n",
    "<img src=\"../images/curve3.png\">\n",
    "\n",
    "Building up or laying off infrastructure takes time and money, whereas cloud computing is easily scalable to the current demand. As it is assumed to very costly to have excess demand as well as it is costly to be capacity restricted it is economically reasonable to rely on cloud computing services. \n",
    "\n",
    "- AWS: [What is Cloud Computing?](https://aws.amazon.com/de/what-is-cloud-computing/)\n",
    "\n",
    "Benefits: \n",
    "\n",
    "1. Reduced investments and proportional costs (cost reduction)\n",
    "2. Increased scalability (providing simplified capacity planning)\n",
    "3. Increased availability and reliability (providing organizatinal agility)\n",
    "\n",
    "Risks:\n",
    "\n",
    "1. (Potential) Increase in Security Vulnerabilities\n",
    "2. Reduced Operational Governance Control (over cloud resources)\n",
    "3. Limited Portability Between Cloud Providers\n",
    "4. Multi-regional Compliance and Legal Issues\n",
    "\n",
    "### Deployment to Production\n",
    "\n",
    "- Integrate machine learning model into an existing production environment \n",
    "- Model needs to be provided to those responsible for deployment. \n",
    "\n",
    "In the following we will assume taht the machine learning model was developed in Python. \n",
    "\n",
    "Three primary methods used to transfer a model from the modeling component to the deployment component (least to most commonly used): \n",
    "\n",
    "- Python model is recorded into the programming langauge of the production environment\n",
    "- Model is coded in Predictive Model Markpu Language (PMML) or Portable Format Analytics (PFA)\n",
    "- Python model is converted into a format that can be used in the production environment (i.e. SageMaker).\n",
    " - Use libraries and methods that convert the model into code that can be used in the production environment like PyTorch, TensorFlow, Scikit-Learn, etc. that convert Python models intot he intermediate standard format, such as [Open Neural Network Exchange](https://onnx.ai/) format.\n",
    " - This standard format can be converted into the software native of the production environment. \n",
    " \n",
    "The last one is the easierst and fastesst way to move a Python Model from modeling directly to deployment: \n",
    "\n",
    "- Typical way to move models into the production environoment\n",
    "- Technologies like *containers*, *endpoints* and *APIs* (Application Programming Interfaces) also help ease the work required for deploying a model into production environment. \n",
    "\n",
    "In earlier stages development was typically handled by analysts, whereas operations (deployment) was handled by software developers responsible for the production environment. \n",
    "\n",
    "Recently, this division between development and operations softens enabling analysts to handle certain aspects of deployment and enables faster updates to faltering models. \n",
    "\n",
    "Advances in cloud services, like [SageMaker](https://aws.amazon.com/sagemaker/) and [ML Engine](https://cloud.google.com/ml-engine/), and deployment technologies, like Containers and REST APIs, allow for analysts to easily take on the responsibilities of deployment. \n",
    "\n",
    "### Production Environments\n",
    "\n",
    "- Endpoint: Interface to the model\n",
    "- The interface (enpoint) facilitates an ease of communication between the modle and the application.\n",
    "\n",
    "<img src=\"../images/endpoint2.png\">\n",
    "\n",
    "One way to think of the **endpoint** that acts as this interface: \n",
    "\n",
    "- **endpoint** itself if like a function call\n",
    "- the **function** itself would be the model and\n",
    "- the **Python program** is the application\n",
    "\n",
    "Similar to the example above:\n",
    "\n",
    "- **Endpoint** accepts user data as the **input** and **returns** the model's prediction based upon this input through the endpoint (similar to a function call)\n",
    "- In the example, the user data is the input argument and the prediction is the returned value from the function call. \n",
    "- The **application**, here is the **python program**, displays the model's prediction to the application user. \n",
    "\n",
    "The endpoint itself is just the interface between the model and the application. \n",
    "\n",
    "- interface enables users to get predictions from the deployed model based on their user data. \n",
    "\n",
    "#### How does the endpoint (interface) facilitates communication between application and model?\n",
    "\n",
    "Application and model communicate throught he endpoint (interface). The enpoint is an Application Programming Interface (API). \n",
    "\n",
    "- API: set of rules that enable programs (here the application and the model) to communicate with each other\n",
    "\n",
    "Here, the *API* uses a **RE**presentational **S**tate **T**ransfer, **REST** architecture that provides a framework for the set of rules and constraints that mus be adhered to for communication betweeen programs. \n",
    "\n",
    "- Hypertext Transfer Protocol (HTTP): application protocol for distributed, collaborative, hypermedia information systems. Foundation of data communication for WWW. \n",
    "- **REST API** is one that uses HTTP requests and responses to enable communication between the application and the model through the endpoint (interface). \n",
    "- **HTTP request** and **HTTP response** are communications sent between the application and model. \n",
    "\n",
    "#### HTTP request\n",
    "\n",
    "HTTP request sent from applicaion to model consists of four parts: \n",
    "\n",
    "- Enpoint: Endpoint in the form of a Uniform Resource Locator (URL), aka web address\n",
    "- HTTP method: Four **HTTP methods**. For deployment of our application we'll use the **POST method**.\n",
    "- HTTP Headers: The **headers** will contain additional information (like data format within the message) that's passed to the receiving program. \n",
    "- Message (Data or Body): The final part is the **message** (data or body); for deployment this will contain the user's data which is input into the model. \n",
    "\n",
    "<img src=\"../images/httpmethods.png\">\n",
    "\n",
    "#### HTTP response\n",
    "\n",
    "Sent from model to your application and is composed of three parts: \n",
    "\n",
    "- HTTP Status Code: If successfully received and processed the user's data that was sent in the **message** status code should start with a 2 (i.e. 200)\n",
    "- HTTP Headers: The headers will contain additional information, like format of the data within the message, thats passed to the receiving program. \n",
    "- Message (Data or Body): What's returnes as the data within the message is the prediction that's provided by the model. \n",
    "\n",
    "The prediction is then presented to the application user through the application. The enpoint is the interface that enables communication between the application and the model using a **REST API**. \n",
    "\n",
    "#### Whats's application's reponsibility?\n",
    "\n",
    "- Format the user's data to put into the HTTP request message and be used by the model\n",
    "- Translate predictions from the HTTP response message in a way that's easy for the application user's to understand. \n",
    "\n",
    "Information included in the HTTP messages sent between **application** and **model**: \n",
    "\n",
    "- User's data will need to be in a CSV or JSON format with a specific ordering of the data. Ordering depends on the used model. \n",
    "- Often predictions will be returned in CSV or JSON format with a specific ordering of the returned predictions. Ordering depends on the used model. \n",
    "\n",
    "## Containers\n",
    "\n",
    "So far, two primary programs, the **model** and the **application**, that communicate with each other through the **endpoint (interface)**\n",
    "\n",
    "<img src=\"../images/endpoint3.png\">\n",
    "\n",
    "- What is the **model**? The model is the Python model that's created, trained, and evaluated in the modeling component of the machine learning workflow.\n",
    "- What is the **application**? The application is a web or software that enables the users to use the model to retrieve predictions.\n",
    "\n",
    "Both, model and application, require a computing environment. One way to create this environment is to use **containers**. Containers are created using a script that contains instructions on which software packages, libraries, and other computing attributes are needed in order to run a software application, in our case either the model or application. \n",
    "\n",
    "####  But what is a container?\n",
    "\n",
    "> A container can be thought of as a standardized collection/bundle of software that is to be used for the specific purpose of running an application. \n",
    "\n",
    "A common container software is [Docker](www.docker.com). \n",
    "\n",
    "### Containers, explained\n",
    "\n",
    "Shipping container analogy:\n",
    "\n",
    "- Shipping container can contain a wide variety of products\n",
    "- Structure of a shipping container provides the ability to hold different types of products\n",
    "\n",
    "Docker containers:\n",
    "\n",
    "- Can contain all types of different software. \n",
    "- Structure of a Docker **container** enables the **container** to be created, saved, used, and deleted through a set of common tools. \n",
    "- The common tool set works with **any container** regardless of the software the **container** contains. \n",
    "\n",
    "The image below shows three containers running three different applications\n",
    "\n",
    "<img src=\"../images/container.png\">\n",
    "\n",
    "This architecture provides the following advantages:\n",
    "\n",
    "- Isolates the application, which increases security\n",
    "- Requires only software neede to run the application, which uses computational resources more efficiently and allows for faster application deployment. \n",
    "- Makes application creation, replication, delection, and maintenance easier and the same across all applicatinos that are deployed using containers. \n",
    "- Provides a more simple and secure way to replicate, save, and share containers. \n",
    "\n",
    "A container script file is used to create a container. \n",
    "\n",
    "- Can easily be shared with others, provides a simple method to replicate a particular container. \n",
    "- The container script is simply the instructiuons (algorithm) that is used to create a container. For *Docker*, these files are called *dockerfiles*. \n",
    "\n",
    "<img src=\"../images/container2.png\">\n",
    "\n",
    "- Container engine uses a container script to create a container for an application to run within.\n",
    "- These container script files can be stored in repositories, which provide a simple means to share and replicate containers. \n",
    "- Docker: [Docker Hub](https://hub.docker.com/explore/) is the official repository for storing and sharing dockerfiles. \n",
    "- Example of a dockerfile: [Link](https://github.com/pytorch/pytorch/blob/master/docker/pytorch/Dockerfile)\n",
    " - The dockerfile creates a docker container with Python 3.6 and PyTorch installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics of Deployment and Modeling\n",
    "\n",
    "#### What is Deployment?\n",
    "\n",
    "Method that integrates a machine learnin model into an existing production environment so that the model can be used to make decisions or predictions based upon data input into this model. \n",
    "\n",
    "#### Whas is a production environment?\n",
    "\n",
    "A production environment can be thought of as a web, mobile, or other software application that is currently being used by many people and must respond quickly to those users' requests. \n",
    "\n",
    "### Characteristics of modeling\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "In ML, a hyperparameters is a parameter whose value cannot be estimated from the data: \n",
    "\n",
    "- Not learned through the estimators. \n",
    "- Must be set by the developer\n",
    "- Hyperparameter tuning is an important part of model training. \n",
    "- Cloud platform machine learning services often provide methods that allow for automatic hyperparameter tuning for use with model training\n",
    "- Without automatic hyperparameter option, one option is to use methods from scikit-learn Python library for hyperparameters tuning ([link](https://scikit-learn.org/stable/modules/grid_search.html#).\n",
    "\n",
    "### Characteristics of Deployment\n",
    "\n",
    "#### Model Versioning\n",
    "\n",
    "- Saving model version as model's metadata in database\n",
    "- deployment platform should indicate a deployed model's version. \n",
    "\n",
    "#### Model Monitoring\n",
    "\n",
    "- Monitor the performance of the model\n",
    "- Application may need to be updated\n",
    "\n",
    "#### Model Updating and Routing\n",
    "\n",
    "Another characteristic: \n",
    "\n",
    "- Ability to update deployed model\n",
    "- If the monitoring process shows that performance metrics are not met the model requires updating. \n",
    "- Change in the data generating process: Collect these data to update the model\n",
    "- Routing: To allow comparison of performance between the deployed model variants, routing should be supported.\n",
    "\n",
    "#### Model Predictions\n",
    "\n",
    "Two common type of predictions provided by the deployed model. \n",
    "\n",
    "- On-demand predictions (online, real-time, synchronous predictions) \n",
    " - Predictions are returned in the response from the request. Often, these requests and responses are done through an API using JSON or XML formatted strings.\n",
    " - Commonly used to provide real-time, online responsen based upon a deployed model. \n",
    "- Batch predictions (asynchronous, batch-based predictions)\n",
    " - One expects high volume of requests with more periodic submissions, latency won't be an issue. \n",
    " - Batch request points to specifically formatted data file or request and will return the predictions to a file. Cloud services require these files will be stored in the cloud provider's cloud. \n",
    " - Batch predictions are commonly used to help make business decisions (i.e. for weekly reports). \n",
    "\n",
    "<img src=\"../images/mlworkflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Cloud Providers\n",
    "\n",
    "Focus on [Amazon's SageMaker](https://aws.amazon.com/sagemaker/). Similar to SageMaker is [Google's ML Engine](https://cloud.google.com/ml-engine/). \n",
    "\n",
    "### Amazon Web Services (AWS)\n",
    "\n",
    "Amazon's cloud service to build, train, and deploy ML models. \n",
    "\n",
    "Advantages: \n",
    "\n",
    "- Use of any programming language or software framework for building, training, and deploying amchine learning model in AWS\n",
    "- [Built-in algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html) - Various built-in algorithms, e.g. \n",
    " - for discrete classification or quantitative analysis using [linear learner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) or \n",
    " - [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html)\n",
    " - item recommendations using [factorization machine](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html), \n",
    " - grouping based upon attributes using [K-Means](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means.html), \n",
    " - an algorithm for [image classification](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html)\n",
    " - Time Series Analysis with [DeepAR](https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/deepar.html)\n",
    "- Custom Algorithms - Different programming languages and software frameworks that can be used to develop custom algorithms\n",
    " - [PyTorch](https://docs.aws.amazon.com/sagemaker/latest/dg/pytorch.html), [TensorFlow](https://docs.aws.amazon.com/sagemaker/latest/dg/tf.html), [Apache Spark](https://docs.aws.amazon.com/sagemaker/latest/dg/mxnet.html), and [Chainer](https://docs.aws.amazon.com/sagemaker/latest/dg/chainer.html)\n",
    "- [Own algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html) - Use your own algorithm when it isn't included within the built-in or custom algorithms above\n",
    "\n",
    "In addition, the use of [Jupyter Notebooks](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html) is enabled and there are the following additional features and automated tools that make modeling and deployment easier:\n",
    "\n",
    "- [Automatic Model Tuning: SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) - Feature for hyperparameter tuning of built-in and custom algorithms. In addition, SageMaker provides evaluation metrics for buil-in algorithms\n",
    "- [Monitoring Models in Sagemaker](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-overview.html) - Features to monitor your deployed models. One can choose how much traffic to route to each deployed model (model variant). \n",
    " - More information on routing: [here](https://docs.aws.amazon.com/sagemaker/latest/dg/API_ProductionVariant.html) and [here](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateEndpointConfig.html)\n",
    "- Type of Predictions - SageMaker allows for [On-demand](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-test-model.html) type of predictions whre each prediction request can contain one to many requestst. SageMaker also allows for [Batch](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) predictions, and request data size limits are based upon S3 object size limits. \n",
    "\n",
    "### Google Cloud Platform (GCP)\n",
    "\n",
    "[Google cloud Platform (GCP) ML Engine](https://cloud.google.com/ml-engine/) is Google's cloud service. **Similarities** and **differences:** \n",
    "\n",
    "- Prediction costs: [ML Engine pricing](https://cloud.google.com/ml-engine/docs/pricing#node-hour) vs. Sagemaker pricing.\n",
    "- Ability to explore and process data: Jupyter Notebooks are not available within ML Engine\n",
    " - To use Jupyter Notebooks within GCP, one would use [Datalab](https://cloud.google.com/datalab/docs/) can be used to explore and transform raw data into clean data for analysis and processing, \n",
    " - [DataFlow](https://cloud.google.com/dataflow/docs/) can be used to deploy batch and streaming dta processing pipelines\n",
    " - AWS also has data processing and transformation pipeline services: [AWS Glue](https://aws.amazon.com/glue/) and [AWS Data Pipeline](https://aws.amazon.com/datapipeline/)\n",
    "- Machine Learning Software: [Google's ML Engine](https://cloud.google.com/ml-engine/) has less flexibility in available software frameworks for building, training, and deploying machine learning models in GCP, compared to Amazon's SageMaker. \n",
    "\n",
    "The two available software frameworks for modeling within **ML Engine**: \n",
    "\n",
    "- [Google's TensorFlow](https://cloud.google.com/ml-engine/docs/tensorflow/) - Keras is a higher level API written in Python taht runs on top of TF. \n",
    " - [TensorFlow examples](https://cloud.google.com/ml-engine/docs/tensorflow/samples)\n",
    " - [Keras example](https://cloud.google.com/ml-engine/docs/tensorflow/samples#census-keras)\n",
    "- [Google's Scikit-learn](https://cloud.google.com/ml-engine/docs/scikit/) and [XGBoost Python package](https://xgboost.readthedocs.io/en/latest/python/index.html) can be used together for creating, training, and deploying machine learning models. \n",
    " - In [Google's example](https://cloud.google.com/ml-engine/docs/scikit/training-xgboost) XGBoost is used for modeling and Scikit-learn is used for processing the data. \n",
    "\n",
    "Flexibility in Modeling and Deployment\n",
    "\n",
    "- [Automatic Model Tuning](https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning-overview)\n",
    "- [Monitoring Models](https://cloud.google.com/ml-engine/docs/tensorflow/monitor-training)\n",
    "- Type of predictions - ML Engine allows for [Online](https://cloud.google.com/ml-engine/docs/tensorflow/online-predict) type of predictions whre each prediction request can contain one to many requests. ML Engine also allows for [Batch](https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict) predictions. For more information: [Online and Batch predictions](https://cloud.google.com/ml-engine/docs/tensorflow/online-vs-batch-prediction)\n",
    "\n",
    "### Other frameworks\n",
    "\n",
    "- Microsoft Azure\n",
    " - [Azure AI](https://azure.microsoft.com/en-us/overview/ai-platform/#platform)\n",
    " - [Azure Machine Learning Studio](https://azure.microsoft.com/en-us/services/machine-learning-studio/)\n",
    "- [Paperspace](https://www.paperspace.com/ml) - simply provides GPU-backed virtual machines with industry standard software tools\n",
    " - Claims to provide more powerful and less expensive virtual machines than AWS, GCP or Azure\n",
    "- [Cloud Foundry](https://www.cloudfoundry.org/) - open source cloud application platform\n",
    "\n",
    "## Summary - Cloud Computing\n",
    "\n",
    "- Cloud computing - Transforming an IT product into a service\n",
    "- Deployment - Making model available for predictions through applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Computing Defined\n",
    "\n",
    "<img src=\"../images/nistcloud.png\">\n",
    "\n",
    "The graphic above is from the Naional Institute of Standards and Technology (NIST) and its definition of cloud computing has three levels: \n",
    "\n",
    "- Service Models\n",
    "- Deployment Models\n",
    "- Essential Characteristics\n",
    "\n",
    "### Service Models\n",
    "\n",
    "#### Software as a Service (SaaS)\n",
    "\n",
    "<img src=\"../images/cloud_saas.png\">\n",
    "\n",
    "The yellow dashed line in the graphic shows with SaaS, the only customer responsibilities are those attributed to a \"user\" and all other responsibilties are placed on the cloud provider. \n",
    "\n",
    "Software as a product (i.e. a physical copy like a cd) has become rare. \n",
    "\n",
    "Other examples of SaaS:\n",
    "\n",
    "- email applications\n",
    "- storage applications\n",
    "\n",
    "#### Platform as a Service (PaaS)\n",
    "\n",
    "<img src=\"../images/cloud_paas.png\">\n",
    "\n",
    "Examples: \n",
    "\n",
    "- Services that allow to easily build, host, monitor, and scale their applications using their platform. \n",
    "- i.e. build and host an e-commerce website. \n",
    "\n",
    "#### Infrastructure as a Service (IaaS)\n",
    "\n",
    "with IaaS the customer has most responsibility beyond those associated with running secure data centers and maintaining the hardware and software that enables IaaS. \n",
    "\n",
    "<img src=\"../images/cloud_iaas.png\">\n",
    "    \n",
    "Examples:\n",
    "\n",
    "- AWS, Rackspace\n",
    "\n",
    "IaaS enables the customer to provisioning computer processing, storage, networks, other fundamental computing resources\n",
    "\n",
    "### Deployment Models of Cloud Computing\n",
    "\n",
    "<img src=\"../images/deploymentmodels.png\">\n",
    "\n",
    "### Essential Characteristics\n",
    "\n",
    "<img src=\"../images/essentialcharacteristics.png\">\n",
    "\n",
    "## ...\n",
    "\n",
    "(left out the second optional part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[NbConvertApp] Converting notebook Introdution to Deployment.ipynb to html',\n",
       " '[NbConvertApp] Writing 280499 bytes to Introdution to Deployment.html']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!jupyter nbconvert \"Introdution to Deployment\".ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
